{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Create some raw documents\n",
    "raw_documents = [\"I love tacos.\",\n",
    "                \"She ran with the chicken.\",\n",
    "                \"I don't choose to take a nap. The nap chooses me.\",\n",
    "                \"That man is nice as pie with ice cream.\",\n",
    "                \"This pizza is an affront to nature.\"]\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "def get_tokens(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "sentences = [get_tokens(r) for r in raw_documents]\n",
    "w2v_model = Word2Vec(sentences, min_count=1, vector_size=5)\n",
    "\n",
    "# from gensim.models import KeyedVectors\n",
    "# sentences = [get_tokens(r) for r in raw_documents]\n",
    "# models = KeyedVectors.Word2Vec(sentences, min_count=1, vector_size=5)\n",
    "\n",
    "model = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03156241  0.00643374 -0.08279715 -0.15364872 -0.03017141]\n",
      "[-0.192071    0.10014586 -0.17519173 -0.0878365  -0.000702  ]\n",
      "[-0.00592365 -0.1532248   0.19229484  0.09964113  0.18466286]\n"
     ]
    }
   ],
   "source": [
    "print(model['ran'])\n",
    "print(model['love'])\n",
    "print(model['tacos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', 'nap', 'is', 'with', 'to', 'I', 'ice', 'pie', 'love', 'tacos']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(model.index_to_key)\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('me', 0.8187951445579529),\n",
       " ('choose', 0.7246150970458984),\n",
       " ('pizza', 0.5813791155815125),\n",
       " ('take', 0.5290067195892334),\n",
       " ('man', 0.5207754969596863),\n",
       " ('chooses', 0.5118007659912109),\n",
       " ('to', 0.4151745140552521),\n",
       " ('affront', 0.3722187280654907),\n",
       " ('as', 0.3721567392349243),\n",
       " ('This', 0.27691811323165894)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('tacos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert gensim.models.doc2vec.FAST_VERSION > -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "texts = fetch_20newsgroups(subset='train')\n",
    "dir(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(texts.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "[7 4 4 ... 3 1 8]\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(len(texts.target))\n",
    "print(texts.target)\n",
    "print(texts.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = texts.data\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', ':', 'lerxst', '@', 'wam.umd.edu', '(', 'where', \"'s\", 'my', 'thing', ')', 'subject', ':', 'what', 'car', 'is', 'this', '!', '?', 'nntp-posting-host', ':', 'rac3.wam.umd.edu', 'organization', ':', 'university', 'of', 'maryland', ',', 'college', 'park', 'lines', ':', '15', 'i', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'i', 'saw', 'the', 'other', 'day', '.', 'it', 'was', 'a', '2-door', 'sports', 'car', ',', 'looked', 'to', 'be', 'from', 'the', 'late', '60s/', 'early', '70s', '.', 'it', 'was', 'called', 'a', 'bricklin', '.', 'the', 'doors', 'were', 'really', 'small', '.', 'in', 'addition', ',', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', '.', 'this', 'is', 'all', 'i', 'know', '.', 'if', 'anyone', 'can', 'tellme', 'a', 'model', 'name', ',', 'engine', 'specs', ',', 'years', 'of', 'production', ',', 'where', 'this', 'car', 'is', 'made', ',', 'history', ',', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', ',', 'please', 'e-mail', '.', 'thanks', ',', '-', 'il', '--', '--', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst', '--', '--']\n"
     ]
    }
   ],
   "source": [
    "def get_tokens(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return [token.lower() for token in tokens]\n",
    "print(get_tokens(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', ':', 'lerxst', '@', 'wam.umd.edu', '(', 'where', \"'s\", 'my', 'thing', ')', 'subject', ':', 'what', 'car', 'is', 'this', '!', '?', 'nntp-posting-host', ':', 'rac3.wam.umd.edu', 'organization', ':', 'university', 'of', 'maryland', ',', 'college', 'park', 'lines', ':', '15', 'i', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'i', 'saw', 'the', 'other', 'day', '.', 'it', 'was', 'a', '2-door', 'sports', 'car', ',', 'looked', 'to', 'be', 'from', 'the', 'late', '60s/', 'early', '70s', '.', 'it', 'was', 'called', 'a', 'bricklin', '.', 'the', 'doors', 'were', 'really', 'small', '.', 'in', 'addition', ',', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', '.', 'this', 'is', 'all', 'i', 'know', '.', 'if', 'anyone', 'can', 'tellme', 'a', 'model', 'name', ',', 'engine', 'specs', ',', 'years', 'of', 'production', ',', 'where', 'this', 'car', 'is', 'made', ',', 'history', ',', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', ',', 'please', 'e-mail', '.', 'thanks', ',', '-', 'il', '--', '--', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst', '--', '--']\n"
     ]
    }
   ],
   "source": [
    "# We will treat each document as a sentence\n",
    "sentences = [get_tokens(doc) for doc in data]\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ng = gensim.models.word2vec.Word2Vec(sentences, min_count=3, vector_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.8160393238067627),\n",
       " ('god', 0.7183233499526978),\n",
       " ('person', 0.713968813419342),\n",
       " ('christ', 0.7115176320075989),\n",
       " ('child', 0.7097669839859009),\n",
       " ('himself', 0.707438588142395),\n",
       " ('son', 0.7001399397850037),\n",
       " ('father', 0.6979144811630249),\n",
       " ('satan', 0.6964322328567505),\n",
       " ('spirit', 0.6781124472618103)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ng.wv.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "sents = api.load('text8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take some time to complete\n",
    "w2v_model_t8 = gensim.models.word2vec.Word2Vec(sents, min_count=5, vector_size=200, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t8 = w2v_model_t8.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.6409082412719727),\n",
       " ('girl', 0.5279996395111084),\n",
       " ('men', 0.5224376320838928),\n",
       " ('creature', 0.4999851882457733),\n",
       " ('person', 0.49859797954559326),\n",
       " ('loner', 0.4788859188556671),\n",
       " ('sailor', 0.46047475934028625),\n",
       " ('thief', 0.4589238464832306),\n",
       " ('wight', 0.4515334367752075),\n",
       " ('boy', 0.44679781794548035)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t8.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quiet', 0.6112156510353088),\n",
       " ('lucky', 0.5464048385620117),\n",
       " ('laugh', 0.511472225189209),\n",
       " ('merry', 0.5101077556610107),\n",
       " ('glad', 0.48044514656066895),\n",
       " ('shy', 0.4578081965446472),\n",
       " ('fond', 0.4572877585887909),\n",
       " ('sad', 0.45594456791877747),\n",
       " ('proud', 0.455405056476593),\n",
       " ('me', 0.45507529377937317)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t8.most_similar('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.5827288031578064),\n",
       " ('isabella', 0.5057438015937805),\n",
       " ('regent', 0.48734012246131897),\n",
       " ('princess', 0.4863964021205902),\n",
       " ('monarch', 0.48449116945266724),\n",
       " ('eleonora', 0.47063368558883667),\n",
       " ('matilda', 0.4677153527736664),\n",
       " ('consort', 0.4670857787132263),\n",
       " ('throne', 0.4518029987812042),\n",
       " ('kings', 0.4495188593864441)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t8.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall sentences from Newsgroup data\n",
    "sentences = [get_tokens(doc) for doc in texts.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_documents = []\n",
    "for i, sent in enumerate(sentences):\n",
    "    tagged_documents.append(TaggedDocument(sent,[\"sent_{}\".format(i)]))\n",
    "d2v_model = gensim.models.doc2vec.Doc2Vec(tagged_documents, vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slow', 0.6519448757171631),\n",
       " ('cheap', 0.5980238914489746),\n",
       " ('quickly', 0.5742024779319763),\n",
       " ('busy', 0.566688597202301),\n",
       " ('printer', 0.5295618176460266),\n",
       " ('noticable', 0.5183477401733398),\n",
       " ('hot', 0.5129312872886658),\n",
       " ('expensive', 0.511255145072937),\n",
       " ('vacuum', 0.5100240111351013),\n",
       " ('hard', 0.5092251300811768)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.wv.most_similar('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.15149911e-02  1.44660231e-02 -1.78435594e-02  1.85195859e-06\n",
      " -5.51041253e-02 -1.44342445e-02  2.37905839e-03 -1.05397892e-03\n",
      " -9.78821050e-03 -5.52256498e-03  2.30867043e-02 -7.62659265e-03\n",
      "  3.08004837e-03  1.63363482e-04 -1.26051316e-02  5.65508716e-02\n",
      "  3.12219765e-02  1.88399237e-02 -1.66636705e-02  2.56193317e-02\n",
      "  3.68497893e-02 -1.84319559e-02  5.96815087e-02  2.73488332e-02\n",
      "  4.00689431e-02  5.28140552e-03  3.28555442e-02  1.49388835e-02\n",
      "  1.07796034e-02 -8.52395501e-03  8.79813638e-03  2.18394976e-02\n",
      "  2.05100290e-02  1.56416390e-02  2.94732712e-02  4.19249684e-02\n",
      " -3.40541154e-02 -5.16070947e-02 -3.70674208e-03 -1.93846133e-02\n",
      "  3.24069941e-03  2.52944827e-02  2.36536581e-02 -4.47735097e-03\n",
      " -7.70742772e-03  1.49477562e-02 -4.99098841e-03  2.00222265e-02\n",
      "  2.99103325e-03 -3.92838614e-03 -1.28843160e-02  2.65932339e-03\n",
      " -3.40535480e-04 -7.85771757e-03  1.23418923e-02  6.56678975e-02\n",
      " -3.20133567e-02  2.96586915e-03 -1.73135065e-02 -4.25034836e-02\n",
      "  1.74385533e-02 -1.17580881e-02  1.37932478e-02  1.20394630e-02\n",
      "  3.36468592e-02 -3.25914882e-02 -2.00905371e-03 -7.56601850e-03\n",
      " -5.53765185e-02  1.95290800e-02 -1.00116739e-02  3.19128260e-02\n",
      " -3.78561839e-02  2.04277467e-02 -1.17285140e-02  2.86120921e-02\n",
      " -1.99658261e-03 -7.68436072e-03 -2.50142207e-03 -4.40725533e-04\n",
      " -1.32400794e-02 -5.96855059e-02  3.43379378e-02  1.73791684e-02\n",
      "  3.37760001e-02  2.28847936e-02 -1.80346798e-02  4.27069925e-02\n",
      "  3.23042721e-02 -3.27582820e-03  2.35514287e-02  3.61735895e-02\n",
      " -2.55967397e-02 -2.33509801e-02 -1.03617236e-02  4.09795605e-02\n",
      "  3.04302182e-02 -2.60833800e-02 -1.45156793e-02  7.68893510e-02\n",
      "  1.79462098e-02  2.51229908e-02  2.94511728e-02 -4.66113165e-03\n",
      "  4.60861903e-03 -3.65923941e-02  8.76667649e-02  3.59301455e-02\n",
      " -4.87182960e-02  7.16734584e-03 -5.81861008e-03 -4.44175452e-02\n",
      "  1.27838068e-02  1.51956324e-02 -2.51120385e-02  1.15378220e-02\n",
      " -2.34866608e-02 -5.55460621e-03  4.56695557e-02 -3.06579620e-02\n",
      " -7.99807021e-04 -2.16330774e-02  1.75538417e-02 -2.53607072e-02\n",
      " -5.43681905e-03 -1.36388037e-02  3.34423743e-02 -3.11839581e-02\n",
      " -3.28499973e-02 -3.35726216e-02  2.66452786e-02  3.10587529e-02\n",
      " -3.47861610e-02  4.82842475e-02  2.80365311e-02 -2.68061999e-02\n",
      "  3.30156125e-02 -4.34645312e-03 -2.67958883e-02 -2.21951846e-02\n",
      "  4.65148427e-02 -1.68347787e-02 -3.60663570e-02  6.91898866e-03\n",
      " -3.53144594e-02 -2.20775884e-02 -4.39882278e-02  1.58288721e-02\n",
      "  6.96966890e-03 -1.10898484e-02  3.55771147e-02 -4.49082740e-02\n",
      "  2.06138007e-02  2.79295854e-02  5.42876311e-02  1.28474506e-02\n",
      "  5.80195396e-04 -2.45360304e-02  3.62106897e-02 -9.12306737e-03\n",
      "  2.58312449e-02 -2.32203808e-02 -6.69290423e-02 -2.74409484e-02\n",
      " -2.41660364e-02  3.51676270e-02  3.96207534e-02  3.43987122e-02\n",
      "  2.14698957e-03  9.37236398e-02  1.79938842e-02 -1.83836427e-02\n",
      " -1.45182991e-03  3.33486274e-02 -4.07010205e-02  3.44626978e-02\n",
      "  7.96024874e-03 -1.25354510e-02 -6.26159981e-02 -3.45859230e-02\n",
      "  1.52387349e-02  5.53322248e-02 -1.68065559e-02  5.41596748e-02\n",
      " -6.80279359e-02 -1.13288360e-02  1.50491856e-02  3.65067311e-02\n",
      "  3.72109818e-03  2.61273328e-03 -1.64794270e-03 -1.40711814e-02\n",
      " -7.67583493e-03 -3.26077314e-03  2.30938364e-02 -7.56119788e-02\n",
      "  7.26648141e-04 -4.86814342e-02  4.01331484e-02  3.78493220e-03\n",
      "  2.30609179e-02  3.40892971e-02  1.34871928e-02  5.70683647e-03\n",
      " -7.24987360e-04  9.17182863e-03  3.27772349e-02  1.72910001e-02\n",
      " -5.61895780e-02  4.40847911e-02 -9.20768175e-03 -7.59438872e-02\n",
      "  3.63099314e-02 -1.18908101e-05  1.22740585e-02 -5.32424301e-02\n",
      " -9.70618520e-03 -2.42136512e-02 -1.95290782e-02 -1.90910120e-02\n",
      " -1.37952641e-02  2.74595432e-02 -1.43408533e-02 -3.08861341e-02\n",
      " -2.11688057e-02 -3.04052066e-02 -1.91114545e-02  2.34863255e-02\n",
      " -3.62687819e-02 -5.47271734e-03  1.20864259e-02  3.29622999e-02\n",
      " -6.42796652e-03  1.18524274e-02 -1.15697309e-02  2.21914686e-02\n",
      " -8.07752181e-03  2.39815307e-03  8.77443468e-04  2.11503692e-02\n",
      "  7.21996883e-03 -5.23664476e-03  1.06263449e-02  3.49855125e-02\n",
      " -1.68911535e-02  3.26037779e-03  7.28280144e-03 -7.04410113e-03\n",
      " -5.87075762e-03 -7.32554728e-03  2.79662758e-02  1.74483396e-02\n",
      " -1.38808079e-02  1.26648573e-02 -2.35529318e-02 -1.19472397e-02\n",
      " -1.47229657e-02  4.43126680e-03 -8.90446361e-03  2.64589749e-02\n",
      "  3.23398001e-02  2.14332733e-02  1.41100427e-02 -5.52268364e-02\n",
      " -5.24177868e-03 -4.02780734e-02 -6.30636467e-03  3.51388007e-03\n",
      " -1.82332899e-02 -9.33832396e-03 -1.00859199e-02  1.41631849e-02\n",
      " -1.18619045e-02 -5.61489211e-03  3.12824994e-02  2.57467367e-02\n",
      " -1.31190685e-03 -9.05495952e-04 -4.91524860e-02 -1.37586929e-02\n",
      " -4.52277102e-02  3.40220518e-02  4.59960774e-02  2.93320548e-02\n",
      " -3.17603350e-02 -1.66376736e-02 -5.11976779e-02 -2.45680474e-02\n",
      " -1.26391789e-02 -3.79694835e-03  1.31692681e-02  4.21902910e-02\n",
      " -1.53952383e-03 -1.67682320e-02  1.70873348e-02  7.77045405e-03\n",
      " -4.48147804e-02 -3.73484604e-02  5.77284547e-04 -2.98508792e-03]\n"
     ]
    }
   ],
   "source": [
    "vec0 = d2v_model.infer_vector('i love tacos'.split())\n",
    "print(vec0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sent_7978', 0.8453588485717773),\n",
       " ('sent_9797', 0.8379197120666504),\n",
       " ('sent_8571', 0.8346693515777588),\n",
       " ('sent_336', 0.8324801921844482),\n",
       " ('sent_3362', 0.829128086566925),\n",
       " ('sent_2882', 0.8287025690078735),\n",
       " ('sent_3436', 0.8263554573059082),\n",
       " ('sent_10169', 0.8252823352813721),\n",
       " ('sent_1184', 0.8212636709213257),\n",
       " ('sent_4285', 0.8208652138710022)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.dv.most_similar([vec0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
